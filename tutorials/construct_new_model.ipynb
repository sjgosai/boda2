{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec118925-12e7-4808-9e5f-4c7c0a875812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning.pytorch as ptl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import boda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c19de6-c871-4378-8144-f6580c3850c2",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664cd9d-7bed-4257-9da2-9ea7759ee20f",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb094585-8a1c-4b7a-988f-250a685b55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/CODA_resources/MPRA_ALL_HD_v2.txt...\n",
      "/ [1 files][311.6 MiB/311.6 MiB]                                                \n",
      "Operation completed over 1 objects/311.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://tewhey-public-data/CODA_resources/MPRA_ALL_HD_v2.txt ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca67283-514e-40a6-a673-2f15665d61b8",
   "metadata": {},
   "source": [
    "## Pick modules\n",
    "Pick modules to define:\n",
    "1. The data, how it's preprocessed and train/val/test split\n",
    "2. The model, the architecture setup, loss function, etc.\n",
    "3. The graph, how the data is used to train the model (i.e. training loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd28d039-763d-4e2f-a89e-8246d1d96dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = boda.data.MPRA_DataModule\n",
    "model_module= boda.model.BassetBranched\n",
    "graph_module= boda.graph.CNNBasicTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae98f7-b611-4502-96af-437b481457c8",
   "metadata": {},
   "source": [
    "## Initalize Data and Model\n",
    "I added chr1 to test and chr2 to val to speed up this example. I also removed the reverse complmentat data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624f6e3b-f87a-43eb-a9e5-be5d735cba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_module(\n",
    "    datafile_path='MPRA_ALL_HD_v2.txt', \n",
    "    synth_val_pct=0.0, synth_test_pct=99.98,\n",
    "    val_chrs=['2','19','21','X'], test_chrs=['1','7','13'], \n",
    "    activity_columns=['HepG2_mean', 'SKNSH_mean'],\n",
    "    batch_size=1024, padded_seq_len=600, \n",
    "    use_reverse_complements=False, \n",
    "    duplication_cutoff=2.0, \n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "model = model_module(\n",
    "    n_outputs=2, \n",
    "    n_linear_layers=1, linear_channels=1000,\n",
    "    linear_activation='ReLU', linear_dropout_p=0.12, \n",
    "    n_branched_layers=3, branched_channels=140, \n",
    "    branched_activation='ReLU', branched_dropout_p=0.56, \n",
    "    loss_criterion='L1KLmixed', loss_args={'beta':5.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893e23c-e199-4785-99fc-fe9931585968",
   "metadata": {},
   "source": [
    "## Append Graph to Model\n",
    "Augment the model class to append functions from the graph module. A downside to this structure is that you need to make sure all relevent Graph args are defined (even if None is an acceptable default). This is because the `__init__` block in the Graph class doesn't run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ebbdf8-c962-4287-b460-c9da88e93114",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_args = {\n",
    "    'optimizer': 'Adam', \n",
    "    'optimizer_args': {\n",
    "        'lr': 0.0033, 'betas':[0.9, 0.999], \n",
    "        'weight_decay': 3.43e-4, 'amsgrad': True\n",
    "    },\n",
    "    'scheduler': 'CosineAnnealingWarmRestarts', \n",
    "    'scheduler_monitor': None, \n",
    "    'scheduler_interval': 'step',\n",
    "    'scheduler_args': {\n",
    "        'T_0': 4096,\n",
    "    }\n",
    "}\n",
    "\n",
    "graph = graph_module(\n",
    "    model = model,\n",
    "    **graph_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdf630f-7581-4135-a4e9-24cdc433ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0438, -0.0434],\n",
       "        [-0.0434, -0.0435],\n",
       "        [-0.0437, -0.0432],\n",
       "        [-0.0438, -0.0430],\n",
       "        [-0.0436, -0.0430],\n",
       "        [-0.0437, -0.0426],\n",
       "        [-0.0438, -0.0431],\n",
       "        [-0.0436, -0.0427],\n",
       "        [-0.0435, -0.0431],\n",
       "        [-0.0437, -0.0430]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(10,4,600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90002f10-7e19-43d0-a065-af48622cc594",
   "metadata": {},
   "source": [
    "## Lightning trainer\n",
    "Normally we train for more epochs, but reduced in this example. Update `min_epochs` and `max_epochs` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eeaabe9-cd76-4c96-b27d-c9d7e7774f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=1, \n",
    "    monitor='prediction_mean_spearman', \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "stopping_callback = EarlyStopping(\n",
    "    monitor='prediction_mean_spearman', \n",
    "    patience=5,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "    accelerator='gpu', devices=1, \n",
    "    min_epochs=2, max_epochs=5, # <- we use min_epochs=60, max_epochs=200\n",
    "    precision=16, callbacks= [\n",
    "        checkpoint_callback,\n",
    "        stopping_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed051228-22c9-428f-a50e-6cadaecf5d66",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d673c3-38bf-47a6-82dd-79683e8198b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "HepG2 | top cut value: 10.76, bottom cut value: -5.73\n",
      "SKNSH | top cut value: 11.34, bottom cut value: -6.38\n",
      "\n",
      "Number of examples discarded from top: 0\n",
      "Number of examples discarded from bottom: 0\n",
      "\n",
      "Number of examples available: 693349\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Padding sequences... \n",
      "\n",
      "Creating train/val/test datasets with tokenized sequences... \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Number of examples in train: 500043 (72.12%)\n",
      "Number of examples in val:   105586 (15.23%)\n",
      "Number of examples in test:  134597 (19.41%)\n",
      "\n",
      "Excluded from train: -46877 (-6.76)%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | BassetBranched | 3.9 M \n",
      "1 | criterion | L1KLmixed      | 0     \n",
      "---------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "7.855     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3927422 parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.13488 | harmonic_mean_loss: 1.34746 | prediction_mean_spearman: -0.00810 | entropy_spearman: 0.00821 |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2917: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:236: UserWarning: You called `self.log('current_epoch', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  f\"You called `self.log({self.meta.name!r}, ...)` in your `{self.meta.fx}` but the value needs to\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7123788208940ee86f2dbe34b21d2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.13315 | harmonic_mean_loss: 0.98369 | prediction_mean_spearman: 0.52003 | entropy_spearman: 0.13899 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.11380 | harmonic_mean_loss: 0.72063 | prediction_mean_spearman: 0.64639 | entropy_spearman: 0.13519 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.10897 | harmonic_mean_loss: 0.66356 | prediction_mean_spearman: 0.67312 | entropy_spearman: 0.22520 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.09974 | harmonic_mean_loss: 0.60111 | prediction_mean_spearman: 0.69441 | entropy_spearman: 0.19438 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.09436 | harmonic_mean_loss: 0.57196 | prediction_mean_spearman: 0.71202 | entropy_spearman: 0.24907 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(graph, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b36ff31-b576-4359-baa6-b9a4aca8d8da",
   "metadata": {},
   "source": [
    "## Reload best epoch and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1bf75a6-1237-410f-9da0-7650c58cf327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model stashed at: /home/ubuntu/boda2/tutorials/lightning_logs/version_10/checkpoints/epoch=4-step=2445.ckpt\n",
      "Exists: True\n",
      "Setting model from epoch: 4\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def set_best(my_model, callbacks):\n",
    "    \"\"\"\n",
    "    Set the best model checkpoint for the provided model.\n",
    "\n",
    "    This function sets the state of the provided model to the state of the best checkpoint,\n",
    "    as determined by the `ModelCheckpoint` callback.\n",
    "\n",
    "    Args:\n",
    "        my_model (nn.Module): The model to be updated.\n",
    "        callbacks (dict): Dictionary of callbacks, including 'model_checkpoint'.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The updated model.\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        try:\n",
    "            best_path = callbacks['model_checkpoint'].best_model_path\n",
    "            get_epoch = re.search('epoch=(\\d*)', best_path).group(1)\n",
    "            if 'gs://' in best_path:\n",
    "                subprocess.call(['gsutil','cp',best_path,tmpdirname])\n",
    "                best_path = os.path.join( tmpdirname, os.path.basename(best_path) )\n",
    "            print(f'Best model stashed at: {best_path}', file=sys.stderr)\n",
    "            print(f'Exists: {os.path.isfile(best_path)}', file=sys.stderr)\n",
    "            ckpt = torch.load( best_path )\n",
    "            my_model.load_state_dict( ckpt['state_dict'] )\n",
    "            print(f'Setting model from epoch: {get_epoch}', file=sys.stderr)\n",
    "        except KeyError:\n",
    "            print('Setting most recent model', file=sys.stderr)\n",
    "    return my_model\n",
    "\n",
    "graph = set_best(graph, {'model_checkpoint': checkpoint_callback})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c262468f-5f2f-481c-94ba-2d66b7f362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(graph.model.state_dict(), 'example_new_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb13b33-6fbb-493f-830b-db67b6d411a0",
   "metadata": {},
   "source": [
    "## load the save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e82ecb-99a9-4a3a-9a07-7cc47053720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BassetBranched(\n",
       "  (pad1): ConstantPad1d(padding=(9, 9), value=0.0)\n",
       "  (conv1): Conv1dNorm(\n",
       "    (conv): Conv1d(4, 300, kernel_size=(19,), stride=(1,))\n",
       "    (bn_layer): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pad2): ConstantPad1d(padding=(5, 5), value=0.0)\n",
       "  (conv2): Conv1dNorm(\n",
       "    (conv): Conv1d(300, 200, kernel_size=(11,), stride=(1,))\n",
       "    (bn_layer): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pad3): ConstantPad1d(padding=(3, 3), value=0.0)\n",
       "  (conv3): Conv1dNorm(\n",
       "    (conv): Conv1d(200, 200, kernel_size=(7,), stride=(1,))\n",
       "    (bn_layer): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pad4): ConstantPad1d(padding=(1, 1), value=0.0)\n",
       "  (maxpool_3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (maxpool_4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear1): LinearNorm(\n",
       "    (linear): Linear(in_features=2600, out_features=1000, bias=True)\n",
       "    (bn_layer): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (branched): BranchedLinear(\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.56, inplace=False)\n",
       "    (intake): RepeatLayer()\n",
       "    (branched_layer_1): GroupedLinear()\n",
       "    (branched_layer_2): GroupedLinear()\n",
       "    (branched_layer_3): GroupedLinear()\n",
       "  )\n",
       "  (output): GroupedLinear()\n",
       "  (nonlin): ReLU()\n",
       "  (dropout): Dropout(p=0.12, inplace=False)\n",
       "  (criterion): L1KLmixed(\n",
       "    (MSE): L1Loss()\n",
       "    (KL): KLDivLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = model_module(\n",
    "    n_outputs=2, \n",
    "    n_linear_layers=1, linear_channels=1000,\n",
    "    linear_activation='ReLU', linear_dropout_p=0.12, \n",
    "    n_branched_layers=3, branched_channels=140, \n",
    "    branched_activation='ReLU', branched_dropout_p=0.56, \n",
    "    loss_criterion='L1KLmixed', loss_args={'beta':5.0}\n",
    ")\n",
    "\n",
    "new_model.load_state_dict(torch.load('example_new_model.pt'))\n",
    "new_model.eval()\n",
    "new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4a1cbd-afe0-4580-91dc-dea1be088008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.9641, 78.7475],\n",
       "        [41.8193, 54.0374],\n",
       "        [43.6598, 56.1638],\n",
       "        [47.4649, 60.5813],\n",
       "        [48.1967, 56.3398]], device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model( torch.randn(5,4,600).cuda() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
